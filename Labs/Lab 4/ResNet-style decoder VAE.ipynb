{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28be073-a0d2-4db9-a2d4-213f242bded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (3.17.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script gdown.exe is installed in 'C:\\Users\\sarat\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824978f8-5b23-41c4-8178-1efa08bf0d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n",
      "From (redirected): https://drive.usercontent.google.com/download?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM&confirm=t&uuid=f3e66224-3d1f-498f-8de1-e831d86e287c\n",
      "To: C:\\Users\\sarat\\data\\celeba\\img_align_celeba.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.44G/1.44G [00:26<00:00, 55.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U\n",
      "To: C:\\Users\\sarat\\data\\celeba\\list_attr_celeba.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 26.7M/26.7M [00:00<00:00, 33.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\n",
      "To: C:\\Users\\sarat\\data\\celeba\\identity_CelebA.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3.42M/3.42M [00:00<00:00, 17.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=0B7EVK8r0v71pbThiMVRxWXZ4dU0\n",
      "To: C:\\Users\\sarat\\data\\celeba\\list_bbox_celeba.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 6.08M/6.08M [00:00<00:00, 11.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=0B7EVK8r0v71pd0FJY3Blby1HUTQ\n",
      "To: C:\\Users\\sarat\\data\\celeba\\list_landmarks_align_celeba.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 12.2M/12.2M [00:00<00:00, 38.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=0B7EVK8r0v71pY0NSMzRuSXJEVkk\n",
      "To: C:\\Users\\sarat\\data\\celeba\\list_eval_partition.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2.84M/2.84M [00:00<00:00, 12.5MB/s]\n",
      "C:\\Users\\sarat\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | beta=0.00 | Loss:177.96  Recon:177.96  KL:5753.33\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Single-file ConvVAE with a ResNet-style decoder.\n",
    "\n",
    "- Default dataset: CIFAR-10 (3x32x32).\n",
    "- To switch to CelebA (aligned) at 64x64, set DATASET_NAME = 'celeba'.\n",
    "\n",
    "Loss: MSE + beta * KL (with beta warm-up).\n",
    "\n",
    "Usage:\n",
    "  - Run as-is to train on CIFAR-10.\n",
    "  - Switch to CelebA by setting DATASET_NAME='celeba'. Downloads ~1.3GB.\n",
    "  - Visualizations: reconstructions + samples after training.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "DATASET_NAME = 'celeba'  # 'cifar10' or 'celeba'\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if DATASET_NAME.lower() == 'celeba':\n",
    "    IMG_SIZE = 64\n",
    "    IN_CH = 3\n",
    "    LATENT_DIM = 128\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 60\n",
    "else:\n",
    "    IMG_SIZE = 32\n",
    "    IN_CH = 3\n",
    "    LATENT_DIM = 64\n",
    "    BATCH_SIZE = 128\n",
    "    EPOCHS = 50\n",
    "\n",
    "LR = 1e-3\n",
    "BETA_START, BETA_END = 0.0, 1.0\n",
    "WARMUP_EPOCHS = 10\n",
    "\n",
    "# ----------------------------\n",
    "# Data\n",
    "# ----------------------------\n",
    "if DATASET_NAME.lower() == 'celeba':\n",
    "    # CelebA aligned faces; we'll center-crop and resize to 64x64\n",
    "    transform = transforms.Compose([\n",
    "        transforms.CenterCrop(140),\n",
    "        transforms.Resize(64),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_set = datasets.CelebA(\n",
    "        root='./data', split='train', target_type='attr', download=True, transform=transform\n",
    "    )\n",
    "else:\n",
    "    # CIFAR-10 at 32x32\n",
    "    transform = transforms.ToTensor()\n",
    "    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Building blocks\n",
    "# ----------------------------\n",
    "class UpResBlock(nn.Module):\n",
    "    \"\"\"Residual upsampling block: nearest-neighbor upsample + (Conv-BN-ReLU)x2 with skip.\n",
    "    in_ch -> out_ch, spatial size x2.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_up = self.upsample(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x_up)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        skip = self.skip(x_up)\n",
    "        out = F.relu(out + skip)\n",
    "        return out\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Simple strided conv downsampling block with BN+ReLU.\"\"\"\n",
    "    def __init__(self, in_ch: int, out_ch: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "# ----------------------------\n",
    "# Encoder (shared for 32 or 64)\n",
    "# ----------------------------\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, img_size: int, latent_dim: int):\n",
    "        super().__init__()\n",
    "        # compute how many downsamples to get to 4x4\n",
    "        n_down = int(math.log2(img_size)) - 2  # 32->3, 64->4\n",
    "        chs = [64, 128, 256, 512][:n_down]\n",
    "\n",
    "        blocks = []\n",
    "        prev = in_ch\n",
    "        for c in chs:\n",
    "            blocks.append(DownBlock(prev, c))\n",
    "            prev = c\n",
    "        self.net = nn.Sequential(*blocks)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.final_ch = chs[-1]\n",
    "        self.fc_mu = nn.Linear(self.final_ch * 4 * 4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.final_ch * 4 * 4, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.net(x)  # (B, final_ch, 4, 4)\n",
    "        h = self.flatten(h)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "# ----------------------------\n",
    "# ResNet-style Decoder (upsampling with residual blocks)\n",
    "# ----------------------------\n",
    "class ResNetDecoder(nn.Module):\n",
    "    def __init__(self, out_ch: int, img_size: int, latent_dim: int, base_ch_seq=None):\n",
    "        super().__init__()\n",
    "        # Determine the channel progression to mirror the encoder\n",
    "        n_up = int(math.log2(img_size)) - 2  # 32->3, 64->4\n",
    "        if base_ch_seq is None:\n",
    "            base_ch_seq = [64, 128, 256, 512][:n_up]  # encoder channels\n",
    "        # Start from the deepest channel\n",
    "        deep_ch = base_ch_seq[-1]\n",
    "\n",
    "        self.fc = nn.Linear(latent_dim, deep_ch * 4 * 4)\n",
    "\n",
    "        # Build upsampling stages from deep -> shallow\n",
    "        ups = []\n",
    "        in_ch = deep_ch\n",
    "        for ch in reversed(base_ch_seq[:-1]):  # e.g., [256, 128] for 32x32\n",
    "            ups.append(UpResBlock(in_ch, ch))\n",
    "            in_ch = ch\n",
    "        # Final stage to reach the target spatial size\n",
    "        ups.append(UpResBlock(in_ch, base_ch_seq[0]))\n",
    "        in_ch = base_ch_seq[0]\n",
    "\n",
    "        self.ups = nn.Sequential(*ups)\n",
    "        self.to_img = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1)  # logits / mean\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.fc(z)\n",
    "        h = h.view(-1, h.shape[1] // (4*4), 4, 4)\n",
    "        h = self.ups(h)\n",
    "        pred = self.to_img(h)\n",
    "        return pred\n",
    "\n",
    "# ----------------------------\n",
    "# VAE wrapper\n",
    "# ----------------------------\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, in_ch: int, img_size: int, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder(in_ch, img_size, latent_dim)\n",
    "        # match decoder channel plan to encoder\n",
    "        n_down = int(math.log2(img_size)) - 2\n",
    "        base_ch_seq = [64, 128, 256, 512][:n_down]\n",
    "        self.decoder = ResNetDecoder(out_ch=in_ch, img_size=img_size, latent_dim=latent_dim, base_ch_seq=base_ch_seq)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        pred = self.decoder(z)\n",
    "        return pred, mu, logvar\n",
    "\n",
    "# ----------------------------\n",
    "# Loss: MSE + beta*KL\n",
    "# ----------------------------\n",
    "def vae_loss_mse(pred, x, mu, logvar, beta=1.0):\n",
    "    recon = F.mse_loss(pred, x, reduction='sum')\n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon + beta * kl, recon, kl\n",
    "\n",
    "# ----------------------------\n",
    "# Train\n",
    "# ----------------------------\n",
    "model = ConvVAE(IN_CH, IMG_SIZE, LATENT_DIM).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "\n",
    "train_losses, recon_losses, kl_losses = [], [], []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    beta = BETA_START + (BETA_END - BETA_START) * min(1.0, epoch / WARMUP_EPOCHS)\n",
    "    total, tot_recon, tot_kl = 0.0, 0.0, 0.0\n",
    "\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred, mu, logvar = model(x)\n",
    "        loss, r, k = vae_loss_mse(pred, x, mu, logvar, beta=beta)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "        tot_recon += r.item()\n",
    "        tot_kl += k.item()\n",
    "\n",
    "    N = len(train_loader.dataset)\n",
    "    train_losses.append(total / N)\n",
    "    recon_losses.append(tot_recon / N)\n",
    "    kl_losses.append(tot_kl / N)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | beta={beta:.2f} | Loss:{total/N:.2f}  Recon:{tot_recon/N:.2f}  KL:{tot_kl/N:.2f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Plot losses\n",
    "# ----------------------------\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Total')\n",
    "plt.plot(recon_losses, label='Recon')\n",
    "plt.plot(kl_losses, label='KL')\n",
    "plt.title(f\"{DATASET_NAME.upper()} ConvVAE (ResNet decoder) Training\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Per-sample loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Reconstructions\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x, _ = next(iter(train_loader))\n",
    "    x = x[:8].to(device)\n",
    "    pred, _, _ = model(x)\n",
    "    view = pred.sigmoid().clamp(0, 1).cpu()  # for nicer viewing only\n",
    "\n",
    "fig, axs = plt.subplots(2, 8, figsize=(12, 4))\n",
    "for i in range(8):\n",
    "    axs[0, i].imshow(x[i].permute(1, 2, 0).detach().cpu())\n",
    "    axs[0, i].axis('off')\n",
    "    axs[1, i].imshow(view[i].permute(1, 2, 0))\n",
    "    axs[1, i].axis('off')\n",
    "plt.suptitle(\"Top: originals | Bottom: reconstructions\")\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Sampling\n",
    "# ----------------------------\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(16, LATENT_DIM, device=device)\n",
    "    logits = model.decoder(z)\n",
    "    samples = logits.sigmoid().clamp(0, 1).cpu()\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(samples[i].permute(1, 2, 0))\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"ConvVAE Samples (ResNet-style decoder)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4028f6-e427-4597-bf87-f6ca307e5b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
