{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162cd7fd",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment: CycleGAN — Unpaired **Style Transfer** (Monet ↔ Photo)\n",
    "\n",
    "**Course:** Generative AI  \n",
    "**Topic:** Unpaired Image Translation with CycleGAN  \n",
    "**Estimated Time:** 8–12 hours (coding + experiments + report)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "You will implement and analyze a **CycleGAN** to translate images between **Monet paintings** and **real photos** using *unpaired* data. Focus on getting the **losses** right (LSGAN adversarial, identity, cycle consistency) and on interpreting training behavior.\n",
    "\n",
    "### Learning Objectives\n",
    "- Explain why **cycle consistency** enables unpaired translation.  \n",
    "- Implement **LSGAN** adversarial, **identity**, and **cycle** losses.  \n",
    "- Diagnose artifacts (color shifts, texture leakage) and stabilize training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824f0ad",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup & Utilities\n",
    "Run the cell below to import packages and set up helper functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=8, size=(3,256,256)):\n",
    "    \"\"\"Visualize a grid of images from a [-1,1] normalized tensor.\"\"\"\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    grid = make_grid(image_tensor.detach().cpu().view(-1,*size)[:num_images], nrow=4)\n",
    "    plt.imshow(grid.permute(1,2,0).squeeze())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3cafe",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dataset (Monet2Photo)\n",
    "Place the dataset in the following structure:\n",
    "\n",
    "```\n",
    "monet2photo/\n",
    "  trainA/  # Monet\n",
    "  trainB/  # Photo\n",
    "  testA/\n",
    "  testB/\n",
    "```\n",
    "\n",
    "We will perform Resize→RandomCrop to 256×256 and RandomHorizontalFlip, then normalize to **[-1, 1]**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35228ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Unpaired dataset loader for Monet2Photo with on-the-fly pairing.\"\"\"\n",
    "    def __init__(self, root, transform=None, mode='train'):\n",
    "        self.transform = transform\n",
    "        self.files_A = sorted(glob.glob(os.path.join(root, f'{mode}A/*.*')))\n",
    "        self.files_B = sorted(glob.glob(os.path.join(root, f'{mode}B/*.*')))\n",
    "        if len(self.files_A) > len(self.files_B):\n",
    "            # swap to ensure A is not longer than B\n",
    "            self.files_A, self.files_B = self.files_B, self.files_A\n",
    "        self.new_perm()\n",
    "        assert len(self.files_A) > 0, \"Dataset not found. Ensure monet2photo/trainA and trainB exist!\"\n",
    "\n",
    "    def new_perm(self):\n",
    "        self.randperm = torch.randperm(len(self.files_B))[:len(self.files_A)]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        A = self.transform(Image.open(self.files_A[idx % len(self.files_A)]))\n",
    "        B = self.transform(Image.open(self.files_B[self.randperm[idx]]))\n",
    "        if A.shape[0] != 3: A = A.repeat(3,1,1)\n",
    "        if B.shape[0] != 3: B = B.repeat(3,1,1)\n",
    "        if idx == len(self) - 1: self.new_perm()\n",
    "        return (A-0.5)*2, (B-0.5)*2\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.files_A), len(self.files_B))\n",
    "\n",
    "# Transforms & DataLoader\n",
    "load_shape, target_shape = 286, 256\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize(load_shape),\n",
    "    transforms.RandomCrop(target_shape),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(\"monet2photo\", transform=tfm, mode=\"train\")\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "print(\"Batches per epoch:\", len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba2e9",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Models\n",
    "We use the standard CycleGAN generator with **Residual Blocks** and a **PatchGAN** discriminator. You do not need to change these classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Two convs + InstanceNorm + skip addition.\"\"\"\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, padding_mode='reflect')\n",
    "        self.conv2 = nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, padding_mode='reflect')\n",
    "        self.instancenorm = nn.InstanceNorm2d(in_ch)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.instancenorm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.instancenorm(x)\n",
    "        return identity + x\n",
    "\n",
    "class ContractingBlock(nn.Module):\n",
    "    def __init__(self, in_ch, use_bn=True, kernel_size=3, activation='relu'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, in_ch*2, kernel_size=kernel_size, padding=1, stride=2, padding_mode='reflect')\n",
    "        self.use_bn = use_bn\n",
    "        if use_bn:\n",
    "            self.instancenorm = nn.InstanceNorm2d(in_ch*2)\n",
    "        self.activation = nn.ReLU(inplace=True) if activation=='relu' else nn.LeakyReLU(0.2, inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn: x = self.instancenorm(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "class ExpandingBlock(nn.Module):\n",
    "    def __init__(self, in_ch, use_bn=True):\n",
    "        super().__init__()\n",
    "        self.convT = nn.ConvTranspose2d(in_ch, in_ch//2, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.use_bn = use_bn\n",
    "        if use_bn:\n",
    "            self.instancenorm = nn.InstanceNorm2d(in_ch//2)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.convT(x)\n",
    "        if self.use_bn: x = self.instancenorm(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "class FeatureMapBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=7, padding=3, padding_mode='reflect')\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"2 downs -> 9 res -> 2 ups; tanh output.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, base=64):\n",
    "        super().__init__()\n",
    "        self.upfeature = FeatureMapBlock(in_ch, base)\n",
    "        self.c1 = ContractingBlock(base)\n",
    "        self.c2 = ContractingBlock(base*2)\n",
    "        ch = base*4\n",
    "        self.res = nn.Sequential(*[ResidualBlock(ch) for _ in range(9)])\n",
    "        self.e1 = ExpandingBlock(ch)\n",
    "        self.e2 = ExpandingBlock(base*2)\n",
    "        self.downfeature = FeatureMapBlock(base, out_ch)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        x0 = self.upfeature(x)\n",
    "        x1 = self.c1(x0)\n",
    "        x2 = self.c2(x1)\n",
    "        xr = self.res(x2)\n",
    "        xe1 = self.e1(xr)\n",
    "        xe2 = self.e2(xe1)\n",
    "        out = self.downfeature(xe2)\n",
    "        return self.tanh(out)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"PatchGAN: downsampling conv stack -> 1x1 conv to logits map.\"\"\"\n",
    "    def __init__(self, in_ch, base=64):\n",
    "        super().__init__()\n",
    "        self.upfeature = FeatureMapBlock(in_ch, base)\n",
    "        self.c1 = ContractingBlock(base, use_bn=False, kernel_size=4, activation='lrelu')\n",
    "        self.c2 = ContractingBlock(base*2, kernel_size=4, activation='lrelu')\n",
    "        self.c3 = ContractingBlock(base*4, kernel_size=4, activation='lrelu')\n",
    "        self.final = nn.Conv2d(base*8, 1, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x0 = self.upfeature(x)\n",
    "        x1 = self.c1(x0)\n",
    "        x2 = self.c2(x1)\n",
    "        x3 = self.c3(x2)\n",
    "        return self.final(x3)\n",
    "\n",
    "# Instantiate models\n",
    "gen_AB = Generator(3,3).to(device)  # Monet -> Photo\n",
    "gen_BA = Generator(3,3).to(device)  # Photo -> Monet\n",
    "disc_A = Discriminator(3).to(device) # Domain A (Monet)\n",
    "disc_B = Discriminator(3).to(device) # Domain B (Photo)\n",
    "\n",
    "# Losses & optimizers\n",
    "adv_criterion   = nn.MSELoss()\n",
    "recon_criterion = nn.L1Loss()\n",
    "lr = 2e-4\n",
    "gen_opt  = torch.optim.Adam(list(gen_AB.parameters()) + list(gen_BA.parameters()), lr=lr, betas=(0.5,0.999))\n",
    "discA_opt = torch.optim.Adam(disc_A.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "discB_opt = torch.optim.Adam(disc_B.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "\n",
    "print(\"Models ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb382f7b",
   "metadata": {},
   "source": [
    "\n",
    "## 4) **Student TODOs** — Implement Losses\n",
    "\n",
    "Complete the functions below. We use **LSGAN** objectives (MSE to target 1/0), **identity L1**, and **cycle L1**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea654b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== STUDENT TODO 1: Discriminator Loss (LSGAN) ===============\n",
    "def get_disc_loss(real_X, fake_X, disc_X, adv_criterion):\n",
    "    \"\"\"Return LSGAN discriminator loss: real→1, fake→0 (average the two).\"\"\"\n",
    "    # TODO: Implement using the discriminator outputs on real_X and fake_X (detach fake).\n",
    "    disc_fake = disc_X(fake_X.detach())\n",
    "    loss_fake = adv_criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "    disc_real = disc_X(real_X)\n",
    "    loss_real = adv_criterion(disc_real, torch.ones_like(disc_real))\n",
    "    return (loss_fake + loss_real) / 2\n",
    "\n",
    "# Quick sanity check (shapes)\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1,3,256,256).to(device)\n",
    "    _ = get_disc_loss(dummy, dummy, disc_A, adv_criterion)\n",
    "print(\"Discriminator loss: OK (basic shape check).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3747a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== STUDENT TODO 2: Generator Adversarial Loss (LSGAN) ===============\n",
    "def get_gen_adversarial_loss(real_X, disc_Y, gen_XY, adv_criterion):\n",
    "    \"\"\"Return (loss, fake_Y) where loss = MSE(disc_Y(gen_XY(real_X)) → 1).\"\"\"\n",
    "    # TODO: Implement forward through generator then discriminator to target ones.\n",
    "    fake_Y = gen_XY(real_X)\n",
    "    adv_loss = adv_criterion(disc_Y(fake_Y), torch.ones_like(disc_Y(fake_Y)))\n",
    "    return adv_loss, fake_Y\n",
    "\n",
    "print(\"Generator adversarial loss: OK (compiles).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== STUDENT TODO 3: Identity Loss (L1) ===============\n",
    "def get_identity_loss(real_X, gen_YX, identity_criterion):\n",
    "    \"\"\"Identity mapping: if X is already in domain X, gen_YX(real_X) ≈ real_X.\"\"\"\n",
    "    # TODO: Implement identity pass and L1 to original.\n",
    "    identity_X = gen_YX(real_X)\n",
    "    loss = identity_criterion(identity_X, real_X)\n",
    "    return loss, identity_X\n",
    "\n",
    "print(\"Identity loss: OK (compiles).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cbf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== STUDENT TODO 4: Cycle Consistency Loss (L1) ===============\n",
    "def get_cycle_consistency_loss(real_X, fake_Y, gen_YX, cycle_criterion):\n",
    "    \"\"\"Cycle: X->Y (fake_Y), then Y->X should reconstruct real_X.\"\"\"\n",
    "    # TODO: Implement cycle pass and L1 to original.\n",
    "    cycle_X = gen_YX(fake_Y)\n",
    "    loss = cycle_criterion(cycle_X, real_X)\n",
    "    return loss, cycle_X\n",
    "\n",
    "print(\"Cycle loss: OK (compiles).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============== STUDENT TODO 5: Total Generator Loss ===============\n",
    "def get_gen_loss(real_A, real_B, gen_AB, gen_BA, disc_A, disc_B,\n",
    "                 adv_criterion, identity_criterion, cycle_criterion,\n",
    "                 lambda_identity=0.1, lambda_cycle=10):\n",
    "    \"\"\"\n",
    "    Total gen loss = adv_AB + adv_BA\n",
    "                   + λ_id*(id_A + id_B)\n",
    "                   + λ_cyc*(cyc_A + cyc_B)\n",
    "    Return (total_loss, fake_A, fake_B).\n",
    "    \"\"\"\n",
    "    # TODO: Combine all parts using helper functions above.\n",
    "    adv_BA, fake_A = get_gen_adversarial_loss(real_B, disc_A, gen_BA, adv_criterion)\n",
    "    adv_AB, fake_B = get_gen_adversarial_loss(real_A, disc_B, gen_AB, adv_criterion)\n",
    "\n",
    "    id_A, _ = get_identity_loss(real_A, gen_BA, identity_criterion)\n",
    "    id_B, _ = get_identity_loss(real_B, gen_AB, identity_criterion)\n",
    "\n",
    "    cyc_A, _ = get_cycle_consistency_loss(real_A, fake_B, gen_BA, cycle_criterion)\n",
    "    cyc_B, _ = get_cycle_consistency_loss(real_B, fake_A, gen_AB, cycle_criterion)\n",
    "\n",
    "    total = (adv_AB + adv_BA) + lambda_identity*(id_A + id_B) + lambda_cycle*(cyc_A + cyc_B)\n",
    "    return total, fake_A, fake_B\n",
    "\n",
    "print(\"Total generator loss: OK (compiles).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ad1ad",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Training\n",
    "Use the loop below. Start with 10–20 epochs to verify learning. Increase if you have GPU time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a300f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(n_epochs=20, display_step=200, save_model=False):\n",
    "    step = 0\n",
    "    mean_gen, mean_disc = 0.0, 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        for real_A, real_B in dataloader:\n",
    "            real_A = real_A.to(device); real_B = real_B.to(device)\n",
    "\n",
    "            # ---- Update Discriminator A ----\n",
    "            discA_opt.zero_grad(set_to_none=True)\n",
    "            with torch.no_grad():\n",
    "                fake_A = gen_BA(real_B)\n",
    "            dA_loss = get_disc_loss(real_A, fake_A, disc_A, adv_criterion)\n",
    "            dA_loss.backward()\n",
    "            discA_opt.step()\n",
    "\n",
    "            # ---- Update Discriminator B ----\n",
    "            discB_opt.zero_grad(set_to_none=True)\n",
    "            with torch.no_grad():\n",
    "                fake_B = gen_AB(real_A)\n",
    "            dB_loss = get_disc_loss(real_B, fake_B, disc_B, adv_criterion)\n",
    "            dB_loss.backward()\n",
    "            discB_opt.step()\n",
    "\n",
    "            # ---- Update Generators ----\n",
    "            gen_opt.zero_grad(set_to_none=True)\n",
    "            g_loss, fake_A, fake_B = get_gen_loss(\n",
    "                real_A, real_B, gen_AB, gen_BA, disc_A, disc_B,\n",
    "                adv_criterion, recon_criterion, recon_criterion,\n",
    "                lambda_identity=0.1, lambda_cycle=10\n",
    "            )\n",
    "            g_loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            mean_disc += (dA_loss.item()+dB_loss.item())/2 / display_step\n",
    "            mean_gen  += g_loss.item()/display_step\n",
    "\n",
    "            if step % display_step == 0:\n",
    "                print(f\"Epoch {epoch} Step {step} | G: {mean_gen:.4f} D: {mean_disc:.4f}\")\n",
    "                show_tensor_images(torch.cat([real_A, real_B], dim=0), size=(3,256,256))\n",
    "                show_tensor_images(torch.cat([fake_B, fake_A], dim=0), size=(3,256,256))\n",
    "                mean_gen = 0.0; mean_disc = 0.0\n",
    "                if save_model:\n",
    "                    torch.save({\n",
    "                        'gen_AB': gen_AB.state_dict(), 'gen_BA': gen_BA.state_dict(),\n",
    "                        'gen_opt': gen_opt.state_dict(),\n",
    "                        'disc_A': disc_A.state_dict(), 'disc_A_opt': discA_opt.state_dict(),\n",
    "                        'disc_B': disc_B.state_dict(), 'disc_B_opt': discB_opt.state_dict()\n",
    "                    }, f\"cycleGAN_{step}.pth\")\n",
    "            step += 1\n",
    "\n",
    "# Uncomment to train\n",
    "# train(n_epochs=20, display_step=200, save_model=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db446911",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Required Experiments (Ablations)\n",
    "Perform **two** ablations:\n",
    "\n",
    "1) **Cycle weight sweep:** `λ_cyc ∈ {5, 10, 20}` (keep `λ_id=0.1`).  \n",
    "   - Qualitative: Compare structure retention vs. stylization strength.  \n",
    "   - Quantitative proxy: mean **L1 cycle error** on 50 samples per setting.\n",
    "\n",
    "2) **Identity on/off:** `λ_id ∈ {0.0, 0.1}` (keep `λ_cyc=10`).  \n",
    "   - Comment on **color fidelity** and hue preservation.\n",
    "\n",
    "*(Optional)* Try a stabilizer (fake-image replay buffer, one-sided label smoothing, LR decay) and note the effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea1233",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Report Expectations (2–4 pages, professional)\n",
    "\n",
    "**1. Method (≤1 page)**  \n",
    "- Briefly describe CycleGAN (two generators, two discriminators, cycle & identity).  \n",
    "- Include short equations for **LSGAN**, **identity**, and **cycle** losses.\n",
    "\n",
    "**2. Experimental Setup**  \n",
    "- Dataset (Monet vs Photo), image size, augmentations.  \n",
    "- Hyperparameters: λ_cyc, λ_id, optimizer (Adam β₁=0.5, β₂=0.999), LR, hardware.\n",
    "\n",
    "**3. Results**  \n",
    "- Grids: `A→B` (Monet→Photo) and `B→A` (Photo→Monet) at two training points.  \n",
    "- **Cycle reconstructions**: `A→B→A`, `B→A→B` (5–8 examples).  \n",
    "- Loss curves (G and D).  \n",
    "- L1 cycle error table for ablations.\n",
    "\n",
    "**4. Discussion**  \n",
    "- Effect of `λ_cyc` on faithfulness vs stylization.  \n",
    "- Effect of `λ_id` on color preservation.  \n",
    "- Artifacts and any stabilizers tried.\n",
    "\n",
    "**5. Conclusion**  \n",
    "- Key takeaways on unpaired translation and loss trade-offs; contrast with paired Pix2Pix.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
